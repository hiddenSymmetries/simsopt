"""
This module contains the a number of useful functions for using 
the permanent magnets functionality in the SIMSOPT code.
"""
__all__ = ['read_focus_coils', 'coil_optimization',
           'trace_fieldlines', 'make_qfm',
           'calculate_modB_on_major_radius',
           'make_Bnormal_plots',
           ]

import numpy as np
from scipy.optimize import minimize
from pathlib import Path

# Necessary imports for the pareto scans 
import matplotlib.pyplot as plt
import glob
import json
import os
import pandas as pd
import time

def read_focus_coils(filename):
    """
    Reads in the coils from a FOCUS file. For instance, this is
    used for loading in the MUSE phased TF coils.

    Args:
        filename: String denoting the name of the coils file. 

    Returns:
        coils: List of CurveXYZFourier class objects.
        base_currents: List of Current class objects.
        ncoils: Integer representing the number of coils.
    """
    from simsopt.geo import CurveXYZFourier
    from simsopt.field import Current

    ncoils = np.loadtxt(filename, skiprows=1, max_rows=1, dtype=int)
    order = int(np.loadtxt(filename, skiprows=8, max_rows=1, dtype=int))
    coilcurrents = np.zeros(ncoils)
    xc = np.zeros((ncoils, order + 1))
    xs = np.zeros((ncoils, order + 1))
    yc = np.zeros((ncoils, order + 1))
    ys = np.zeros((ncoils, order + 1))
    zc = np.zeros((ncoils, order + 1))
    zs = np.zeros((ncoils, order + 1))
    # load in coil currents and fourier representations of (x, y, z)
    for i in range(ncoils):
        coilcurrents[i] = np.loadtxt(filename, skiprows=6 + 14 * i, max_rows=1, usecols=1)
        xc[i, :] = np.loadtxt(filename, skiprows=10 + 14 * i, max_rows=1, usecols=range(order + 1))
        xs[i, :] = np.loadtxt(filename, skiprows=11 + 14 * i, max_rows=1, usecols=range(order + 1))
        yc[i, :] = np.loadtxt(filename, skiprows=12 + 14 * i, max_rows=1, usecols=range(order + 1))
        ys[i, :] = np.loadtxt(filename, skiprows=13 + 14 * i, max_rows=1, usecols=range(order + 1))
        zc[i, :] = np.loadtxt(filename, skiprows=14 + 14 * i, max_rows=1, usecols=range(order + 1))
        zs[i, :] = np.loadtxt(filename, skiprows=15 + 14 * i, max_rows=1, usecols=range(order + 1))

    # CurveXYZFourier wants data in order sin_x, cos_x, sin_y, cos_y, ...
    coil_data = np.zeros((order + 1, ncoils * 6))
    for i in range(ncoils):
        coil_data[:, i * 6 + 0] = xs[i, :]
        coil_data[:, i * 6 + 1] = xc[i, :]
        coil_data[:, i * 6 + 2] = ys[i, :]
        coil_data[:, i * 6 + 3] = yc[i, :]
        coil_data[:, i * 6 + 4] = zs[i, :]
        coil_data[:, i * 6 + 5] = zc[i, :]

    # Set the degrees of freedom in the coil objects
    base_currents = [Current(coilcurrents[i]) for i in range(ncoils)]
    ppp = 20
    coils = [CurveXYZFourier(order*ppp, order) for i in range(ncoils)]
    for ic in range(ncoils):
        dofs = coils[ic].dofs_matrix
        dofs[0][0] = coil_data[0, 6*ic + 1]
        dofs[1][0] = coil_data[0, 6*ic + 3]
        dofs[2][0] = coil_data[0, 6*ic + 5]
        for io in range(0, min(order, coil_data.shape[0]-1)):
            dofs[0][2*io+1] = coil_data[io+1, 6*ic + 0]
            dofs[0][2*io+2] = coil_data[io+1, 6*ic + 1]
            dofs[1][2*io+1] = coil_data[io+1, 6*ic + 2]
            dofs[1][2*io+2] = coil_data[io+1, 6*ic + 3]
            dofs[2][2*io+1] = coil_data[io+1, 6*ic + 4]
            dofs[2][2*io+2] = coil_data[io+1, 6*ic + 5]
        coils[ic].local_x = np.concatenate(dofs)
    return coils, base_currents, ncoils


def coil_optimization(s, bs, base_curves, curves, out_dir=''):
    """
    Optimize the coils for the QA, QH, or other configurations.

    Args:
        s: plasma boundary.
        bs: Biot Savart class object, presumably representing the
          magnetic fields generated by the coils.
        base_curves: List of CurveXYZFourier class objects.
        curves: List of Curve class objects.
        out_dir: Path or string for the output directory for saved files.

    Returns:
        bs: Biot Savart class object, presumably representing the
          OPTIMIZED magnetic fields generated by the coils.
    """

    from simsopt.geo import CurveLength, CurveCurveDistance, \
        MeanSquaredCurvature, LpCurveCurvature, CurveSurfaceDistance
    from simsopt.objectives import QuadraticPenalty
    from simsopt.geo import curves_to_vtk
    from simsopt.objectives import SquaredFlux

    out_dir = Path(out_dir)
    nphi = len(s.quadpoints_phi)
    ntheta = len(s.quadpoints_theta)
    ncoils = len(base_curves)

    # Weight on the curve lengths in the objective function:
    LENGTH_WEIGHT = 1

    # Threshold and weight for the coil-to-coil distance penalty in the objective function:
    CC_THRESHOLD = 0.1
    CC_WEIGHT = 1

    # Threshold and weight for the coil-to-surface distance penalty in the objective function:
    CS_THRESHOLD = 1.5
    CS_WEIGHT = 1e-2

    # Threshold and weight for the curvature penalty in the objective function:
    CURVATURE_THRESHOLD = 0.1
    CURVATURE_WEIGHT = 1e-9

    # Threshold and weight for the mean squared curvature penalty in the objective function:
    MSC_THRESHOLD = 0.1
    MSC_WEIGHT = 1e-9

    MAXITER = 500  # number of iterations for minimize

    # Define the objective function:
    Jf = SquaredFlux(s, bs)
    Jls = [CurveLength(c) for c in base_curves]
    Jccdist = CurveCurveDistance(curves, CC_THRESHOLD, num_basecurves=ncoils)
    Jcsdist = CurveSurfaceDistance(curves, s, CS_THRESHOLD)
    Jcs = [LpCurveCurvature(c, 2, CURVATURE_THRESHOLD) for c in base_curves]
    Jmscs = [MeanSquaredCurvature(c) for c in base_curves]

    # Form the total objective function.
    JF = Jf \
        + LENGTH_WEIGHT * sum(Jls) \
        + CC_WEIGHT * Jccdist \
        + CS_WEIGHT * Jcsdist \
        + CURVATURE_WEIGHT * sum(Jcs) \
        + MSC_WEIGHT * sum(QuadraticPenalty(J, MSC_THRESHOLD) for J in Jmscs)

    def fun(dofs):
        """ Function for coil optimization grabbed from stage_two_optimization.py """
        JF.x = dofs
        J = JF.J()
        grad = JF.dJ()
        jf = Jf.J()
        BdotN = np.mean(np.abs(np.sum(bs.B().reshape((nphi, ntheta, 3)) * s.unitnormal(), axis=2)))
        outstr = f"J={J:.1e}, Jf={jf:.1e}, ⟨B·n⟩={BdotN:.1e}"
        cl_string = ", ".join([f"{J.J():.1f}" for J in Jls])
        kap_string = ", ".join(f"{np.max(c.kappa()):.1f}" for c in base_curves)
        msc_string = ", ".join(f"{J.J():.1f}" for J in Jmscs)
        outstr += f", Len=sum([{cl_string}])={sum(J.J() for J in Jls):.1f}, ϰ=[{kap_string}], ∫ϰ²/L=[{msc_string}]"
        outstr += f", C-C-Sep={Jccdist.shortest_distance():.2f}, C-S-Sep={Jcsdist.shortest_distance():.2f}"
        outstr += f", ║∇J║={np.linalg.norm(grad):.1e}"
        print(outstr)
        return J, grad

    print("""
    ################################################################################
    ### Perform a Taylor test ######################################################
    ################################################################################
    """)
    f = fun
    dofs = JF.x
    np.random.seed(1)
    h = np.random.uniform(size=dofs.shape)

    J0, dJ0 = f(dofs)
    dJh = sum(dJ0 * h)
    for eps in [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]:
        J1, _ = f(dofs + eps*h)
        J2, _ = f(dofs - eps*h)
        print("err", (J1-J2)/(2*eps) - dJh)

    print("""
    ################################################################################
    ### Run the optimisation #######################################################
    ################################################################################
    """)
    minimize(fun, dofs, jac=True, method='L-BFGS-B', options={'maxiter': MAXITER, 'maxcor': 300}, tol=1e-15)
    curves_to_vtk(curves, out_dir / "curves_opt")
    bs.set_points(s.gamma().reshape((-1, 3)))
    return bs


def trace_fieldlines(bfield, label, s, comm, out_dir=''):
    """
    Make Poincare plots on a surface as in the trace_fieldlines
    example in the examples/1_Simple/ directory.

    Args:
        bfield: MagneticField or InterpolatedField class object.
        label: Name of the file to write to.
        s: plasma boundary surface.
        comm: MPI COMM_WORLD object for using MPI for tracing.
        out_dir: Path or string for the output directory for saved files.
    """
    from simsopt.field.tracing import compute_fieldlines, \
        plot_poincare_data, \
        IterationStoppingCriterion, SurfaceClassifier

    out_dir = Path(out_dir)

    # set fieldline tracer parameters
    nfieldlines = 4
    tmax_fl = 10000

    R0 = np.linspace(s.get_rc(0, 0), s.get_rc(0, 0) + s.get_rc(1, 0) / 2.0, nfieldlines)
    Z0 = np.zeros(nfieldlines)
    phis = [(i / 4) * (2 * np.pi / s.nfp) for i in range(4)]

    # compute the fieldlines from the initial locations specified above
    sc_fieldline = SurfaceClassifier(s, h=0.05, p=2)
    sc_fieldline.to_vtk(str(out_dir) + 'levelset', h=0.02)

    fieldlines_tys, fieldlines_phi_hits = compute_fieldlines(
        bfield, R0, Z0, tmax=tmax_fl, tol=1e-16, comm=comm,
        phis=phis,
        stopping_criteria=[IterationStoppingCriterion(20000)])

    # make the poincare plots
    if comm is None or comm.rank == 0:
        plot_poincare_data(fieldlines_phi_hits, phis, out_dir / f'poincare_fieldline_{label}.png', dpi=100, surf=s)


def make_qfm(s, Bfield, n_iters=200):
    """
    Given some Bfield generated by dipoles AND a set of TF coils, 
    compute a quadratic flux-minimizing surface (QFMS)
    for the total field configuration on the surface s.

    Args:
        s: plasma boundary surface.
        Bfield: MagneticField or inherited MagneticField class object.

    Returns:
        qfm_surface: The identified QfmSurface class object.
    """
    from simsopt.geo.qfmsurface import QfmSurface
    from simsopt.geo.surfaceobjectives import QfmResidual, Volume

    # weight for the optimization
    constraint_weight = 1e-2

    # First optimize at fixed volume
    qfm = QfmResidual(s, Bfield)
    qfm.J()

    # s.change_resolution(16, 16)
    vol = Volume(s)
    vol_target = vol.J()
    qfm_surface = QfmSurface(Bfield, s, vol, vol_target)

    qfm_surface.minimize_qfm_penalty_constraints_LBFGS(tol=1e-15, maxiter=n_iters,
                                                       constraint_weight=constraint_weight)
    print(f"||vol constraint||={0.5*(s.volume()-vol_target)**2:.8e}, ||residual||={np.linalg.norm(qfm.J()):.8e}")

    constraint_weight = 1e-4
    # repeat the optimization for further convergence
    qfm_surface.minimize_qfm_penalty_constraints_LBFGS(tol=1e-15, maxiter=n_iters,
                                                       constraint_weight=constraint_weight)
    print(f"||vol constraint||={0.5*(s.volume()-vol_target)**2:.8e}, ||residual||={np.linalg.norm(qfm.J()):.8e}")
    return qfm_surface


def calculate_modB_on_major_radius(bs, s):
    """
    Check the average magnetic field strength along the major radius
    (m=n=0 mode of a SurfaceRZFourier object)
    to make sure the configuration is scaled correctly. For highly shaped
    stellarators, this can deviate a bit from the on-axis B field strength.

    Args:
        bs (BiotSavart): MagneticField or BiotSavart class object.
        s (SurfaceRZFourier): plasma boundary surface.

    Returns:
        B0avg (float): Average magnetic field strength along 
          the major radius (m=n=0 mode of a SurfaceRZFourier object) of the device.
    """
    nphi = len(s.quadpoints_phi)
    bspoints = np.zeros((nphi, 3))

    # rescale phi from [0, 1) to [0, 2 * pi)
    phi = s.quadpoints_phi * 2 * np.pi

    R0 = s.get_rc(0, 0)
    for i in range(nphi):
        bspoints[i] = np.array([R0 * np.cos(phi[i]),
                                R0 * np.sin(phi[i]),
                                0.0]
                               )
    bs.set_points(bspoints)
    B0 = np.linalg.norm(bs.B(), axis=-1)
    B0avg = np.mean(np.linalg.norm(bs.B(), axis=-1))
    print("Bmag at R = ", R0, ", Z = 0: ", B0)
    print("toroidally averaged Bmag at R = ", R0, ", Z = 0: ", B0avg)
    return B0avg

def make_Bnormal_plots(bs, s_plot, out_dir='', bs_filename="Bnormal", B_axis=None):
    """
    Plot Bnormal on plasma surface from a MagneticField object.
    Do this quite a bit in the permanent magnet optimization
    and initialization so this is a wrapper function to reduce
    the amount of code.

    Args:
        bs: MagneticField class object.
        s_plot: plasma boundary surface with range = 'full torus'.
        out_dir: Path or string for the output directory for saved files.
        bs_filename: String denoting the name of the output file. 
    """
    out_dir = Path(out_dir)
    nphi = len(s_plot.quadpoints_phi)
    ntheta = len(s_plot.quadpoints_theta)
    bs.set_points(s_plot.gamma().reshape((-1, 3)))
    Bn = np.sum(bs.B().reshape((nphi, ntheta, 3)) * s_plot.unitnormal(), axis=2)[:, :, None]
    if B_axis is not None:
        Bn = Bn / B_axis
    pointData = {"B_N": Bn}
    s_plot.to_vtk(out_dir / bs_filename, extra_data=pointData)

"""
Following functions provide tools for large-scale parameter scans and optimization 
workflows for stellarator coil design using SIMSOPT. It includes routines for:
- Continuation methods for parameter sweeps based on previous optimizations
- Initial random parameter scans for coil optimization
- Stage II force-based optimization with flexible objective construction
- Utility functions for random sampling and data export

Functions:
- continuation: Perform continuation-based parameter sweeps from previous results
- initial_optimizations: Run a batch of initial random parameter optimizations
- initial_optimizations_QH: Like initial_optimizations, but for QH configurations
- optimization: Main routine for stage II force-based coil optimization
- rand: Wrapper function for uniform random sampling

Intended for advanced users automating coil optimization studies and data generation for analysis or machine learning.
"""
def continuation(N=10000, dx=0.05,
                 INPUT_DIR="./output/QA/with-force-penalty/1/pareto/",
                 OUTPUT_DIR="./output/QA/with-force-penalty/2/optimizations/",
                 INPUT_FILE="./inputs/input.LandremanPaul2021_QA",
                 MAXITER=14000):
    """
    Perform a continuation method on a set of previous optimizations, 
    perturbing parameters and rerunning optimizations.

    Parameters
    ----------
    N : int
        Number of new optimizations to run.
    dx : float
        Relative perturbation size for parameters.
    INPUT_DIR : str
        Directory containing previous optimization results (with results.json).
    OUTPUT_DIR : str
        Directory to save new optimization results.
    INPUT_FILE : str
        Path to VMEC input file for the target surface.
    MAXITER : int
        Maximum number of optimizer iterations per job.
    """
    # Read in input optimizations
    results = glob.glob(f"{INPUT_DIR}*/results.json")
    df = pd.DataFrame()
    for results_file in results:
        with open(results_file, "r") as f:
            data = json.load(f)
        # Wrap lists in another list
        for key, value in data.items():
            if isinstance(value, list):
                data[key] = [value]
        df = pd.concat([df, pd.DataFrame(data)], ignore_index=True)

    def perturb(init, parameter):
        "Perturbs a parameter from an initial optimization."
        return np.random.uniform(1-dx, 1+dx) * init[parameter].iloc[0]

    for i in range(N):
        init = df.sample()

        # FIXED PARAMETERS
        ARCLENGTH_WEIGHT = 0.01
        UUID_init_from = init['UUID'].iloc[0]
        ncoils = init['ncoils'].iloc[0]
        order = init['order'].iloc[0]
        R1 = init['R1'].iloc[0]

        # RANDOM PARAMETERS
        CURVATURE_THRESHOLD = perturb(init, 'max_κ_threshold')
        MSC_THRESHOLD = perturb(init, 'msc_threshold')
        CS_THRESHOLD = perturb(init, 'cs_threshold')
        CC_THRESHOLD = perturb(init, 'cc_threshold')
        FORCE_THRESHOLD = perturb(init, 'force_threshold')
        LENGTH_TARGET = perturb(init, 'length_target')

        LENGTH_WEIGHT = perturb(init, 'length_weight')
        CURVATURE_WEIGHT = perturb(init, 'max_κ_weight')
        MSC_WEIGHT = perturb(init, 'msc_weight')
        CS_WEIGHT = perturb(init, 'cs_weight')
        CC_WEIGHT = perturb(init, 'cc_weight')
        FORCE_WEIGHT = perturb(init, 'force_weight')

        # RUNNING THE JOBS
        res, results, coils = optimization(
            OUTPUT_DIR,
            INPUT_FILE,
            R1,
            order,
            ncoils,
            UUID_init_from,
            LENGTH_TARGET,
            LENGTH_WEIGHT,
            CURVATURE_THRESHOLD,
            CURVATURE_WEIGHT,
            MSC_THRESHOLD,
            MSC_WEIGHT,
            CC_THRESHOLD,
            CC_WEIGHT,
            CS_THRESHOLD,
            CS_WEIGHT,
            FORCE_THRESHOLD,
            FORCE_WEIGHT,
            ARCLENGTH_WEIGHT,
            dx=dx,
            MAXITER=MAXITER)

        print(f"Job {i+1} completed with UUID={results['UUID']}")


def initial_optimizations(N=10000, MAXITER=14000,
                          FORCE_OBJ=None,
                          OUTPUT_DIR="./output/QA/with-force-penalty/1/optimizations/",
                          INPUT_FILE="./inputs/input.LandremanPaul2021_QA",
                          debug=False,
                          ncoils=5):
    """
    Perform a batch of initial random parameter optimizations for coil design.

    Parameters
    ----------
    N : int
        Number of optimizations to run.
    with_force : bool
        Whether to include force terms in the objective.
    MAXITER : int
        Maximum number of optimizer iterations per job.
    FORCE_OBJ : class
        Force objective class to use (e.g., LpCurveForce).
    OUTPUT_DIR : str
        Directory to save optimization results.
    INPUT_FILE : str
        Path to VMEC input file for the target surface.
    debug : bool
        If True, print extra diagnostics.
    ncoils : int
        Number of unique coil shapes.
    """
    if FORCE_OBJ is None:
        with_force = False
    else:
        with_force = True

    for i in range(N):
        # FIXED PARAMETERS
        ARCLENGTH_WEIGHT = 0.01
        UUID_init_from = None  # not starting from prev. optimization
        order = 16  # 16 is very high!!!

        # RANDOM PARAMETERS
        R1 = np.random.uniform(0.35, 0.75)
        CURVATURE_THRESHOLD = np.random.uniform(5, 12)
        MSC_THRESHOLD = np.random.uniform(4, 6)
        CS_THRESHOLD = np.random.uniform(0.166, 0.300)
        CC_THRESHOLD = np.random.uniform(0.083, 0.120)
        FORCE_THRESHOLD = np.random.uniform(0, 5e+04)
        LENGTH_TARGET = np.random.uniform(4.9, 5.0)

        LENGTH_WEIGHT = 10.0 ** np.random.uniform(-4, -2)
        CURVATURE_WEIGHT = 10.0 ** np.random.uniform(-9, -5)
        MSC_WEIGHT = 10.0 ** np.random.uniform(-7, -3)
        CS_WEIGHT = 10.0 ** np.random.uniform(-1, 4)
        CC_WEIGHT = 10.0 ** np.random.uniform(2, 5)

        if with_force:
            # (1e-20, 1e-8) for Squared forces
            # (1e-14, 1e-5) for Lpforces or B2Energy
            FORCE_WEIGHT = 10.0 ** np.random.uniform(-13, -8)
        else:
            FORCE_WEIGHT = 0

        # RUNNING THE JOBS
        optimization(
            OUTPUT_DIR,
            INPUT_FILE,
            R1,
            order,
            ncoils,
            UUID_init_from,
            LENGTH_TARGET,
            LENGTH_WEIGHT,
            CURVATURE_THRESHOLD,
            CURVATURE_WEIGHT,
            MSC_THRESHOLD,
            MSC_WEIGHT,
            CC_THRESHOLD,
            CC_WEIGHT,
            CS_THRESHOLD,
            CS_WEIGHT,
            FORCE_THRESHOLD,
            FORCE_WEIGHT,
            FORCE_OBJ,
            ARCLENGTH_WEIGHT,
            with_force=with_force,
            debug=debug,
            MAXITER=MAXITER)

        print(f"Job {i+1} completed")


def initial_optimizations_QH(N=10000, with_force=True, MAXITER=14000,
                             OUTPUT_DIR="./output/QA/with-force-penalty/1/optimizations/",
                             INPUT_FILE="./inputs/input.LandremanPaul2021_QH_magwell_R0=1",
                             ncoils=3):
    """
    Perform a batch of initial random parameter optimizations for QH configurations.

    Parameters
    ----------
    N : int
        Number of optimizations to run.
    with_force : bool
        Whether to include force terms in the objective.
    MAXITER : int
        Maximum number of optimizer iterations per job.
    OUTPUT_DIR : str
        Directory to save optimization results.
    INPUT_FILE : str
        Path to VMEC input file for the target surface.
    ncoils : int
        Number of unique coil shapes.
    """
    for i in range(N):
        # FIXED PARAMETERS
        ARCLENGTH_WEIGHT = 0.01
        UUID_init_from = None  # not starting from prev. optimization
        order = 16

        # RANDOM PARAMETERS
        R1 = np.random.uniform(0.35, 0.75)
        CURVATURE_THRESHOLD = np.random.uniform(5, 12)
        MSC_THRESHOLD = np.random.uniform(4, 6)
        CS_THRESHOLD = np.random.uniform(0.166, 0.300)
        CC_THRESHOLD = np.random.uniform(0.083, 0.120)
        FORCE_THRESHOLD = np.random.uniform(0, 5e+04)
        LENGTH_TARGET = np.random.uniform(4.9, 5.0)

        LENGTH_WEIGHT = 10.0 ** np.random.uniform(-3, -1)
        CURVATURE_WEIGHT = 10.0 ** np.random.uniform(-9, -5)
        MSC_WEIGHT = 10.0 ** np.random.uniform(-5, -1)
        CS_WEIGHT = 10.0 ** np.random.uniform(-1, 4)
        CC_WEIGHT = 10.0 ** np.random.uniform(2, 5)

        if with_force:
            FORCE_WEIGHT = 10.0 ** np.random.uniform(-14, -9)
        else:
            FORCE_WEIGHT = 0

        # RUNNING THE JOBS
        res, results, coils = optimization(
            OUTPUT_DIR,
            INPUT_FILE,
            R1,
            order,
            ncoils,
            UUID_init_from,
            LENGTH_TARGET,
            LENGTH_WEIGHT,
            CURVATURE_THRESHOLD,
            CURVATURE_WEIGHT,
            MSC_THRESHOLD,
            MSC_WEIGHT,
            CC_THRESHOLD,
            CC_WEIGHT,
            CS_THRESHOLD,
            CS_WEIGHT,
            FORCE_THRESHOLD,
            FORCE_WEIGHT,
            ARCLENGTH_WEIGHT,
            MAXITER=MAXITER)

        print(f"Job {i+1} completed with UUID={results['UUID']}")


def optimization(
        OUTPUT_DIR="./output/QA/with-force-penalty/2/optimizations/",
        INPUT_FILE="./inputs/input.LandremanPaul2021_QA",
        R1=0.5,
        order=5,
        ncoils=5,
        UUID_init_from=None,
        LENGTH_TARGET=5.00,
        LENGTH_WEIGHT=1e-03,
        CURVATURE_THRESHOLD=12.0,
        CURVATURE_WEIGHT=1e-08,
        MSC_THRESHOLD=5.00,
        MSC_WEIGHT=1e-04,
        CC_THRESHOLD=0.083,
        CC_WEIGHT=1e+03,
        CS_THRESHOLD=0.166,
        CS_WEIGHT=1e+03,
        FORCE_THRESHOLD=2e+04,
        FORCE_WEIGHT=1e-10,
        FORCE_OBJ=None,
        ARCLENGTH_WEIGHT=1e-2,
        dx=None,
        with_force=True,
        debug=False,
        MAXITER=14000):
    """
    Perform a stage II force-based coil optimization with specified parameters and objectives.

    Parameters
    ----------
    OUTPUT_DIR : str
        Directory to save optimization results.
    INPUT_FILE : str
        Path to VMEC input file for the target surface.
    R1 : float
        Minor radius for initial coil geometry.
    order : int
        Number of Fourier modes for coil parameterization.
    ncoils : int
        Number of unique coil shapes.
    UUID_init_from : str or None
        Universally Unique Identifiers (UUIDs) are standardized 128-bit identifiers that 
        provide a practical way to ensure uniqueness across systems and time.
        UUID of previous optimization to initialize from, or None for random.
    LENGTH_TARGET, LENGTH_WEIGHT, ... : float
        Parameters and weights for objective terms.
    FORCE_OBJ : class
        Force objective class to use (e.g., LpCurveForce).
    ARCLENGTH_WEIGHT : float
        Weight for arclength variation penalty.
    dx : float or None
        Optional perturbation for initialization.
    with_force : bool
        Whether to include force terms in the objective.
    debug : bool
        If True, print extra diagnostics.
    MAXITER : int
        Maximum number of optimizer iterations.

    Returns
    -------
    res : OptimizeResult
        Result object from scipy.optimize.minimize.
    results : dict
        Dictionary of exported optimization results and metrics.
    coils : list
        List of optimized coil objects.
    """
    import uuid
    from simsopt._core.optimizable import load
    from simsopt.field import Current, coils_via_symmetries, BiotSavart, coils_to_vtk
    from simsopt.geo import (
        CurveLength,
        CurveCurveDistance,
        CurveSurfaceDistance,
        MeanSquaredCurvature,
        LpCurveCurvature,
        ArclengthVariation,
        create_equally_spaced_curves,
        SurfaceRZFourier)
    from simsopt.field.selffield import regularization_circ
    from simsopt.objectives import SquaredFlux, QuadraticPenalty
    from simsopt.field.force import coil_force, coil_torque, coil_net_force, coil_net_torque, \
        LpCurveForce, LpCurveTorque, SquaredMeanForce, SquaredMeanTorque, B2Energy

    start_time = time.perf_counter()

    # Initialize the boundary magnetic surface:
    nphi = 32
    ntheta = 32
    s = SurfaceRZFourier.from_vmec_input(INPUT_FILE, range="half period", nphi=nphi, ntheta=ntheta)
    nfp = s.nfp
    R0 = s.get_rc(0, 0)

    # Create a copy of the surface that is closed in theta and phi, and covers the
    # full torus toroidally. This is nice for visualization.
    nphi_big = nphi * 2 * nfp + 1
    ntheta_big = ntheta + 1
    quadpoints_theta = np.linspace(0, 1, ntheta_big)
    quadpoints_phi = np.linspace(0, 1, nphi_big)
    surf_big = SurfaceRZFourier(
        dofs=s.dofs,
        nfp=nfp,
        mpol=s.mpol,
        ntor=s.ntor,
        quadpoints_phi=quadpoints_phi,
        quadpoints_theta=quadpoints_theta,
    )

    def initial_base_curves(R0, R1, order, ncoils):
        return create_equally_spaced_curves(
            ncoils,
            nfp,
            stellsym=True,
            R0=R0,
            R1=R1,
            order=order,
        )

    if UUID_init_from is None:
        base_curves = initial_base_curves(R0, R1, order, ncoils)
        total_current = 3e5
        # Since we know the total sum of currents, we only optimize for ncoils-1
        # currents, and then pick the last one so that they all add up to the correct
        # value.
        base_currents = [Current(total_current / ncoils * 1e-5) * 1e5 for _ in range(ncoils-1)]
        # Above, the factors of 1e-5 and 1e5 are included so the current
        # degrees of freedom are O(1) rather than ~ MA.  The optimization
        # algorithm may not perform well if the dofs are scaled badly.
        total_current = Current(total_current)
        total_current.fix_all()
        base_currents += [total_current - sum(base_currents)]

        coils = coils_via_symmetries(base_curves, base_currents, nfp, 
                                     True, regularizations=[regularization_circ(0.05)] * ncoils)
        base_coils = coils[:ncoils]
        curves = [c.curve for c in coils]

        bs = BiotSavart(coils)
        bs.set_points(s.gamma().reshape((-1, 3)))
    else:
        path = glob.glob(f"../**/{UUID_init_from}/biot_savart.json", recursive=True)[0]
        print("2")
        bs = load(path)
        coils = bs.coils
        curves = [c.curve for c in coils]
        base_coils = coils[:ncoils]
        base_curves = [base_coils[i].curve for i in range(ncoils)]
        base_currents = [base_coils[i].current for i in range(ncoils)]
        bs.set_points(s.gamma().reshape((-1, 3)))

    ###########################################################################
    ## FORM THE OBJECTIVE FUNCTION ############################################

    # Define the individual terms objective function:
    Jf = SquaredFlux(s, bs)
    Jls = [CurveLength(c) for c in base_curves]
    Jccdist = CurveCurveDistance(curves, CC_THRESHOLD, num_basecurves=ncoils)
    Jcsdist = CurveSurfaceDistance(curves, s, CS_THRESHOLD)
    Jcs = [LpCurveCurvature(c, 2, CURVATURE_THRESHOLD) for c in base_curves]
    Jmscs = [MeanSquaredCurvature(c) for c in base_curves]

    try:
        Jforce = FORCE_OBJ(base_coils, coils, p=2, threshold=FORCE_THRESHOLD, downsample=2)
    except:
        try:
            Jforce = FORCE_OBJ(base_coils, coils, downsample=2)
        except:
            Jforce = FORCE_OBJ(coils)  # For B2Energy

    Jals = [ArclengthVariation(c) for c in base_curves]
    Jlength = sum(QuadraticPenalty(Jl, LENGTH_TARGET, "max") for Jl in Jls)

    # Form the total objective function.
    JF = Jf \
        + LENGTH_WEIGHT * Jlength \
        + CC_WEIGHT * Jccdist \
        + CS_WEIGHT * Jcsdist \
        + CURVATURE_WEIGHT * sum(Jcs) \
        + MSC_WEIGHT * sum(QuadraticPenalty(J, MSC_THRESHOLD, "max") for J in Jmscs) \
        + ARCLENGTH_WEIGHT * sum(Jals)

    if with_force:
        JF += FORCE_WEIGHT * Jforce

    ###########################################################################
    ## PERFORM OPTIMIZATION ###################################################

    def fun(dofs):
        JF.x = dofs
        J = JF.J()
        grad = JF.dJ()
        if debug:
            jf = Jf.J()
            length_val = LENGTH_WEIGHT * Jlength.J()
            cc_val = CC_WEIGHT * Jccdist.J()
            cs_val = CS_WEIGHT * Jcsdist.J()
            forces_val = Jforce.J()
            arc_val = sum(Jals).J()
            BdotN = np.mean(np.abs(np.sum(bs.B().reshape((nphi, ntheta, 3)) * s.unitnormal(), axis=2)))
            BdotN_over_B = np.mean(np.abs(np.sum(bs.B().reshape((nphi, ntheta, 3)) * s.unitnormal(), axis=2))
                                   ) / np.mean(bs.AbsB())
            outstr = f"J={J:.1e}, Jf={jf:.1e}, ⟨B·n⟩={BdotN:.1e}, ⟨B·n⟩/⟨B⟩={BdotN_over_B:.1e}"
            valuestr = f"J={J:.2e}, Jf={jf:.2e}"
            cl_string = ", ".join([f"{J.J():.1f}" for J in Jls])
            kap_string = ", ".join(f"{np.max(c.kappa()):.2f}" for c in base_curves)
            msc_string = ", ".join(f"{J.J():.2f}" for J in Jmscs)
            outstr += f", ϰ=[{kap_string}], ∫ϰ²/L=[{msc_string}]"
            outstr += f", Len=sum([{cl_string}])={sum(J.J() for J in Jls):.2f}"
            valuestr += f", LenObj={length_val:.2e}"
            valuestr += f", ccObj={cc_val:.2e}"
            valuestr += f", csObj={cs_val:.2e}"
            valuestr += f", forceObj={FORCE_WEIGHT * forces_val:.2e}"
            valuestr += f", arcObj={ARCLENGTH_WEIGHT * arc_val:.2e}"
            outstr += f", F={forces_val:.2e}"
            outstr += f", arclengthvar={arc_val:.2e}"
            outstr += f", C-C-Sep={Jccdist.shortest_distance():.2f}, C-S-Sep={Jcsdist.shortest_distance():.2f}"
            outstr += f", ║∇J║={np.linalg.norm(grad):.1e}"
            print(outstr)
            print(valuestr)
        return J, grad

    res = minimize(fun, JF.x, jac=True, method='L-BFGS-B',
                   options={'maxiter': MAXITER, 'maxcor': 200}, tol=1e-15)
    JF.x = res.x

    ###########################################################################
    ## EXPORT OPTIMIZATION DATA ###############################################

    # MAKE DIRECTORY FOR EXPORT

    UUID = uuid.uuid4().hex  # unique id for each optimization
    OUTPUT_DIR = OUTPUT_DIR + UUID + "/"  # Directory for output
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # EXPORT VTKS
    coils_to_vtk(coils, OUTPUT_DIR + "coils_opt", close=True)

    bs_big = BiotSavart(coils)
    bs_big.set_points(surf_big.gamma().reshape((-1, 3)))
    pointData = {
        "B_N": np.sum(
            bs_big.B().reshape((nphi_big, ntheta_big, 3)) * surf_big.unitnormal(),
            axis=2,
        )[:, :, None]
    }
    surf_big.to_vtk(OUTPUT_DIR + "surf_opt", extra_data=pointData)

    # SAVE DATA TO JSON
    BdotN = np.mean(np.abs(np.sum(bs.B().reshape((nphi, ntheta, 3)) * s.unitnormal(), axis=2)))
    mean_AbsB = np.mean(bs.AbsB())
    b2energy = B2Energy(coils).J()
    lpcurveforce = LpCurveForce(base_coils, coils, p=2, threshold=FORCE_THRESHOLD, downsample=2).J()
    lpcurvetorque = LpCurveTorque(base_coils, coils, p=2, threshold=FORCE_THRESHOLD, downsample=2).J()
    squaredmeanforce = SquaredMeanForce(base_coils, coils).J()
    squaredmeantorque = SquaredMeanTorque(base_coils, coils).J()
    max_forces = [np.max(np.linalg.norm(coil_force(c, coils), axis=1)) for c in base_coils]
    min_forces = [np.min(np.linalg.norm(coil_force(c, coils), axis=1)) for c in base_coils]
    net_forces = [coil_net_force(c, coils) for c in base_coils]
    max_torques = [np.max(np.linalg.norm(coil_torque(c, coils), axis=1)) for c in base_coils]
    min_torques = [np.min(np.linalg.norm(coil_torque(c, coils), axis=1)) for c in base_coils]
    net_torques = [coil_net_torque(c, coils) for c in base_coils]
    RMS_forces = [np.sqrt(np.mean(np.square(np.linalg.norm(coil_force(c, coils), axis=1)))) for c in base_coils]
    RMS_torques = [np.sqrt(np.mean(np.square(np.linalg.norm(coil_torque(c, coils), axis=1)))) for c in base_coils]
    results = {
        "nfp": nfp,
        "ncoils": int(ncoils),
        "order": int(order),
        "nphi": nphi,
        "ntheta": ntheta,
        "R0": R0,  # if initialized from circles, else None
        "R1": R1,  # if initialized from circles, else None
        "UUID_init": UUID_init_from,  # if initialized from optimization, else None
        "length_target": LENGTH_TARGET,
        "length_weight": LENGTH_WEIGHT,
        "max_κ_threshold": CURVATURE_THRESHOLD,
        "max_κ_weight": CURVATURE_WEIGHT,
        "msc_threshold": MSC_THRESHOLD,
        "msc_weight": MSC_WEIGHT,
        "cc_threshold": CC_THRESHOLD,
        "cc_weight": CC_WEIGHT,
        "cs_threshold": CS_THRESHOLD,
        "cs_weight": CS_WEIGHT,
        "force_threshold": FORCE_THRESHOLD,
        "force_weight": FORCE_WEIGHT,
        "arclength_weight": ARCLENGTH_WEIGHT,
        # For some reason, the following values need to be converted explicitly to floats
        # to avoid issues with JSON serialization.
        "lpcurveforce": float(lpcurveforce),
        "lpcurvetorque": float(lpcurvetorque),
        "squaredmeanforce": float(squaredmeanforce),
        "squaredmeantorque": float(squaredmeantorque),
        "JF": float(JF.J()),
        "Jf": float(Jf.J()),
        "gradient_norm": float(np.linalg.norm(JF.dJ())),
        "lengths": [float(J.J()) for J in Jls],
        "max_length": max(float(J.J()) for J in Jls),
        "max_κ": [float(np.max(c.kappa())) for c in base_curves],
        "max_max_κ": max(np.max(c.kappa()) for c in base_curves),
        "MSCs": [float(J.J()) for J in Jmscs],
        "max_MSC": max(float(J.J()) for J in Jmscs),
        "b2energy": float(b2energy),
        "max_forces": [float(f) for f in max_forces],
        "net_forces": [float(np.linalg.norm(f, axis=-1)) for f in net_forces],
        "max_max_force": max(float(f) for f in max_forces),
        "min_forces": [float(f) for f in min_forces],
        "min_min_force": min(float(f) for f in min_forces),
        "RMS_forces": [float(f) for f in RMS_forces],
        "mean_RMS_force": np.mean([float(f) for f in RMS_forces]),
        "max_torques": [float(f) for f in max_torques],
        "net_torques": [float(np.linalg.norm(f, axis=-1)) for f in net_torques],
        "max_max_torque": max(float(f) for f in max_torques),
        "min_torques": [float(f) for f in min_torques],
        "min_min_torque": min(float(f) for f in min_torques),
        "RMS_torques": [float(f) for f in RMS_torques],
        "mean_RMS_torque": np.mean([float(f) for f in RMS_torques]),
        "arclength_variances": [float(J.J()) for J in Jals],
        "max_arclength_variance": max(float(J.J()) for J in Jals),
        "BdotN": BdotN,
        "mean_AbsB": mean_AbsB,
        "normalized_BdotN": BdotN/mean_AbsB,
        "coil_coil_distance": Jccdist.shortest_distance(),
        "coil_surface_distance": Jcsdist.shortest_distance(),
        "message": res.message,
        "success": res.success,
        "iterations": res.nit,
        "function_evaluations": res.nfev,
        "coil_currents": [c.get_value() for c in base_currents],
        "UUID": UUID,
        "eval_time": time.perf_counter() - start_time,
        "dx": dx
    }

    with open(OUTPUT_DIR + "results.json", "w") as outfile:
        json.dump(results, outfile, indent=2)
    bs.save(OUTPUT_DIR + "biot_savart.json")  # save the optimized coil shapes and currents
    print(time.perf_counter() - start_time)
    # return res, base_coils

    JF._children = set()
    Jf._children = set()
    bs._children = set()
    for c in coils:
        c._children = set()
        c.curve._children = set()
        c.current._children = set()


"""
The below set of scripts performs analysis and visualization for stage-two coil optimization results using force metrics. 
It processes optimization results stored in JSON files, applies engineering and quality filters, 
computes Pareto fronts for selected objectives, and generates summary plots. 
The script is intended for use in advanced coil design studies, although current functionality has been
limited to the Landreman-Paul QA and QH configurations. There is no reason why it cannot be used for other
configurations, but the parameters used for the scans defined in optimization_tools.py would need to be changed.

The assumption is that a large number of optimizations
have already been performed with "python initialization.py" (or sbatch cold_starts.sh to run batch jobs on 
a supercomputer) and the results are stored in the ./output/QA/B2Energy/ or a similar directory. This pareto
scan script was used to generate the results in the papers:

    Hurwitz, S., Landreman, M., Huslage, P. and Kaptanoglu, A., 2025. 
    Electromagnetic coil optimization for reduced Lorentz forces.
    Nuclear Fusion, 65(5), p.056044.
    https://iopscience.iop.org/article/10.1088/1741-4326/adc9bf/meta

    Kaptanoglu, A.A., Wiedman, A., Halpern, J., Hurwitz, S., Paul, E.J. and Landreman, M., 2025. 
    Reactor-scale stellarators with force and torque minimized dipole coils. 
    Nuclear Fusion, 65(4), p.046029.
    https://iopscience.iop.org/article/10.1088/1741-4326/adc318/meta

Main steps:
- Load and concatenate optimization results from a specified directory.
- Filter results based on engineering and quality constraints.
- Compute Pareto-optimal sets for force and field error objectives.
- Optionally copy Pareto-optimal result folders to a new output directory.
- Generate and save histograms and scatter plots for key metrics, colored by various parameters.

Usage:
    python coil_force_pareto_scans.py

Dependencies:
    - optimization_tools (local module)
    - matplotlib
    - pandas
    - numpy
    - paretoset
    - glob, json, shutil, os

"""
def success_plt(df, df_filtered):
    """
    Generate and save histograms comparing distributions of key metrics before and after filtering.

    Parameters
    ----------
    df : pandas.DataFrame
        DataFrame containing all raw optimization results.
    df_filtered : pandas.DataFrame
        DataFrame containing filtered optimization results.

    Returns
    -------
    fig : matplotlib.figure.Figure
        The matplotlib figure object containing the histograms.
    """
    fig = plt.figure(1, figsize=(14.5, 11))
    nrows = 5
    ncols = 5

    def plot_2d_hist(field, log=False, subplot_index=0):
        """
        Plot a histogram for a given field, comparing before and after filtering.

        Parameters
        ----------
        field : str
            The column name to plot.
        log : bool, optional
            Whether to use a logarithmic x-axis (default: False).
        subplot_index : int
            The subplot index in the figure.
        """
        plt.subplot(nrows, ncols, subplot_index)
        nbins = 20
        if log:
            data = df[field]
            bins = np.logspace(np.log10(data.min()), np.log10(data.max()), nbins)
        else:
            bins = nbins
        n, bins, patchs = plt.hist(df[field], bins=bins, label="before filtering")
        plt.hist(df_filtered[field], bins=bins, alpha=1, label="after filtering")
        plt.xlabel(field)
        plt.legend(loc=0, fontsize=6)
        plt.xlim(0, np.mean(df[field]) * 2)
        if log:
            plt.xscale("log")
        plt.savefig('hist.pdf')

    # 2nd entry of each tuple is True if the field should be plotted on a log x-scale.
    fields = (
        ("R1", False),
        ("order", False),
        ("max_max_force", False),
        ("max_length", False),
        ("max_max_κ", False),
        ("max_MSC", False),
        ("coil_coil_distance", False),
        ("coil_surface_distance", False),
        ("length_target", False),
        ("force_threshold", False),
        ("max_κ_threshold", False),
        ("msc_threshold", False),
        ("cc_threshold", False),
        ("cs_threshold", False),
        ("length_weight", True),
        ("max_κ_weight", True),
        ("msc_weight", True),
        ("cc_weight", True),
        ("cs_weight", True),
        ("force_weight", True),
        ('ncoils', False)
    )

    i = 1
    for field, log in fields:
        plot_2d_hist(field, log, i)
        i += 1

    plt.tight_layout()
    return fig

def get_dfs(INPUT_DIR='./output/QA/B2Energy/', OUTPUT_DIR=None):
    """
    Load, filter, and compute Pareto front for coil optimization results. Filtering is 
    done based on the following engineering constraints. Max denotes the maximum over all coils,
    max denotes the maximum over a single coil, mean denotes an average over the plasma surface. 
    These numbers will need to be adjusted for other stellarator configurations and rescaled if 
    the major radius is scaled from the 1 m baseline:

    - Max(coil lengths) < 5 * margin_up
    - Max(max(coil curvatures)) < 12.00 * margin_up
    - Max(mean-squared-curvature) < 6.00 * margin_up
    - Max(coil-coil distance) > 0.083 * margin_low
    - Max(coil-surface distance) > 0.166 * margin_low
    - mean(Abs(B)) > 0.22
    - Max(arclength variance) < 1e-2
    - Coil-surface distance < 0.375
    - Coil-coil distance < 0.15
    - Max(coil length) > 3.0
    - Max(normalized BdotN) < 4e-2
    - Max(max(force)) < 50000

    Parameters
    ----------
    INPUT_DIR : str, optional
        Directory containing optimization result folders with results.json files.
    OUTPUT_DIR : str or None, optional
        If provided, Pareto-optimal result folders will be copied to this directory.

    Returns
    -------
    df : pandas.DataFrame
        DataFrame containing all raw optimization results.
    df_filtered : pandas.DataFrame
        DataFrame containing filtered optimization results.
    df_pareto : pandas.DataFrame
        DataFrame containing Pareto-optimal results (minimizing normalized_BdotN and max_max_force).
    """
    import shutil
    from paretoset import paretoset

    ### STEP 1: Import raw data
    inputs = f"{INPUT_DIR}**/results.json"
    results = glob.glob(inputs, recursive=True)
    dfs = []
    for results_file in results:
        with open(results_file, "r") as f:
            data = json.load(f)
        # Wrap lists in another list
        for key, value in data.items():
            if isinstance(value, list):
                data[key] = [value]
        dfs.append(pd.DataFrame(data))
    df = pd.concat(dfs, ignore_index=True)

    ### STEP 2: Filter the data
    margin_up = 1.5  # the upper bound margin to consider for tolerable engineering constraints
    margin_low = 0.5  # the lower bound margin to consider for tolerable engineering constraints

    df_filtered = df.query(
        # ENGINEERING CONSTRAINTS:
        f"max_length < {5 * margin_up}"
        f"and max_max_κ < {12.00 * margin_up}"
        f"and max_MSC < {6.00 * margin_up}"
        f"and coil_coil_distance > {0.083 * margin_low}"
        f"and coil_surface_distance > {0.166 * margin_low}"
        f"and mean_AbsB > 0.22"  # prevent coils from becoming detached from LCFS
        # FILTERING OUT BAD/UNNECESSARY DATA:
        f"and max_arclength_variance < 1e-2"
        f"and coil_surface_distance < 0.375"
        f"and coil_coil_distance < 0.15"
        f"and max_length > 3.0"
        f"and normalized_BdotN < {4e-2}"
        f"and max_max_force<50000"
    )
    print(df_filtered.keys(), df_filtered[["normalized_BdotN", "max_max_force"]])
    print(paretoset(df_filtered[["normalized_BdotN", "max_max_force"]]))

    ### STEP 3: Generate Pareto front and export UUIDs as .txt
    pareto_mask = paretoset(df_filtered[["normalized_BdotN", "max_max_force"]], sense=[min, min])
    df_pareto = df_filtered[pareto_mask]

    # Copy pareto fronts to a separate folder
    if OUTPUT_DIR is not None:
        if os.path.exists(OUTPUT_DIR):
            shutil.rmtree(OUTPUT_DIR)
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        for UUID in df_pareto['UUID']:
            SOURCE_DIR = glob.glob(f"/**/{UUID}/", recursive=True)[0]
            DEST_DIR = f"{OUTPUT_DIR}{UUID}/"
            shutil.copytree(SOURCE_DIR, DEST_DIR)

    ### Return statement
    return df, df_filtered, df_pareto
